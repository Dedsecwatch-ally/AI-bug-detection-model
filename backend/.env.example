# Ollama Model Configuration
OLLAMA_API_URL=http://localhost:11434
OLLAMA_MODEL=mistral

# Model Parameters (adjust these to tune behavior)
# Temperature: 0-2, Higher = more creative, Lower = more focused
OLLAMA_TEMPERATURE=0.4

# Top P: 0-1, Lower = more deterministic, Higher = more diverse
OLLAMA_TOP_P=0.9

# Top K: 0+, Lower = more precise, Higher = more varied
OLLAMA_TOP_K=40

# Num Predict: Max tokens to generate
OLLAMA_NUM_PREDICT=300

# Repeat Penalty: 1.0 = no penalty, >1.0 = avoid repetition
OLLAMA_REPEAT_PENALTY=1.1

# Quick Presets - uncomment the one you want:

# Preset 1: Very Focused & Precise
# OLLAMA_TEMPERATURE=0.2
# OLLAMA_TOP_P=0.8
# OLLAMA_TOP_K=20
# OLLAMA_NUM_PREDICT=300
# OLLAMA_REPEAT_PENALTY=1.2

# Preset 2: Balanced (Current Default)
# OLLAMA_TEMPERATURE=0.4
# OLLAMA_TOP_P=0.9
# OLLAMA_TOP_K=40
# OLLAMA_NUM_PREDICT=300

# Preset 3: Creative & Detailed
# OLLAMA_TEMPERATURE=0.7
# OLLAMA_TOP_P=0.95
# OLLAMA_TOP_K=50
# OLLAMA_NUM_PREDICT=500

# Preset 4: Quick & Short
# OLLAMA_TEMPERATURE=0.3
# OLLAMA_TOP_P=0.85
# OLLAMA_TOP_K=30
# OLLAMA_NUM_PREDICT=150
